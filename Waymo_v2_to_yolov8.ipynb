{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5fcfbe7-9bf5-4e3f-a74c-24d8d8fcf9c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-26 19:21:33.571721: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-06-26 19:21:33.780767: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-06-26 19:21:33.782695: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-26 19:21:34.699758: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.12.0\n"
     ]
    }
   ],
   "source": [
    "#@title Initial setup\n",
    "from typing import Optional\n",
    "import warnings\n",
    "# Disable annoying warnings from PyArrow using under the hood.\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import dask.dataframe as dd\n",
    "from waymo_open_dataset import v2\n",
    "from waymo_open_dataset.utils import  frame_utils\n",
    "print(tf.__version__)\n",
    "\n",
    "\n",
    "# Path to the directory with all components\n",
    "dataset_dir = '/media/mike/MainDrive/Documents/data/perception_2.0.0/training'\n",
    "\n",
    "context_name = '10023947602400723454_1120_000_1140_000'\n",
    "\n",
    "def read(tag: str) -> dd.DataFrame:\n",
    "  \"\"\"Creates a Dask DataFrame for the component specified by its tag.\"\"\"\n",
    "  paths = tf.io.gfile.glob(f'{dataset_dir}/{tag}/{context_name}.parquet')\n",
    "  return dd.read_parquet(paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9402ac4-fce7-4380-b5f1-5b4f0493d27a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 81 objects on lidar.key.segment_context_name='10023947602400723454_1120_000_1140_000' lidar.key.frame_timestamp_micros=1552440195362591\n",
      "\tlaser_object_id='-U88NMYnocLWCh6iqZwj1g' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='0VCoeT-jjrIfzTCsOWz20A' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='63vjcxiQGxy6SmQ94yX-FQ' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='81faaqjwezt3wc0ZN-1N0g' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='A4kzX4tBck4XcFuUOPA6Lg' camera_object_id='42d3fd29-cc31-44c6-a044-7af1a172488e' camera_name=3.0\n",
      "\tlaser_object_id='CB379cbEIKwW6eAs4wK6mw' camera_object_id='baae00a2-cacd-43c9-9d83-0932920c987e' camera_name=1.0\n",
      "\tlaser_object_id='Iv3M96stRJ3JE-umZR0uVA' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='L5HBM5tSKtNA4qHegDQk8Q' camera_object_id='4b9a9206-fbf1-4d45-8765-197759100bd6' camera_name=1.0\n",
      "\tlaser_object_id='PrS_b18HNPEbxJ9IAYW2BQ' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='YTw2k0_-8UqolJn4WQRc2g' camera_object_id='699b6cb3-afc1-469f-8ac9-40978aeb511b' camera_name=1.0\n",
      "\tlaser_object_id='ZyK_iICxQsEYdJLxMFTw7w' camera_object_id='08b1e19e-b912-4963-a7bb-55e138bbc25e' camera_name=1.0\n",
      "\tlaser_object_id='ZyK_iICxQsEYdJLxMFTw7w' camera_object_id='da518036-17cb-48c4-97aa-97939f989d16' camera_name=3.0\n",
      "\tlaser_object_id='aZNY65GX0cPUkxaWoiYiFA' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='hhuZm4IrFKySygbA_3k80w' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='iYoNqzfcHozgqJVHl7Yxnw' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='jYdxjpZOYqJdSiBQI133Fw' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='l9f--u5kPKABASTzvy9Nug' camera_object_id='d4a7521f-1659-4ef3-a5ce-dc0811a223f6' camera_name=1.0\n",
      "\tlaser_object_id='oq32CII6BSHT6k4uzf5XrA' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='pJ3fmc4NHVFkhDPgGBtS4Q' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='rM0XsOkipsd4-TUUQ5ncsQ' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='t9E-elYgX_LpXadnao0H3Q' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='uTQJwYsr8nw8M5kF2ELaiA' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='wO7bCMlAPPxIZSpihCgJBw' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='wcj6Uo3otoyeYSL_80w-Rw' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='2-A6zakvKX2opVnyx9gplQ' camera_object_id='a6f937a6-7ea8-4393-b636-e0560e699856' camera_name=1.0\n",
      "\tlaser_object_id='2OYKagQRfCdaOXgU5RkMBA' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='3083QteOhZ_vSpxmP0XK-Q' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='38Np8bwqcvw9KkrH3xHfpg' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='3I9vmrICjjnWtavq3ysJrQ' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='8IZ7fkXm0FDeUdEuJAqSlA' camera_object_id='260f57c0-787d-4f36-bfe9-64ca9828448f' camera_name=1.0\n",
      "\tlaser_object_id='EKH1nF9LYmAF7RP2zcpTAw' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='GZswbdmDQZSe88ajnioK_g' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='MGw5mrKnm4f98o1li921HQ' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='OTxlocnBbws-LpK8i2X10w' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='OkBzhxzagapiYam_4NK-9A' camera_object_id='eff781d6-b34f-400b-95ad-b960fa0270d8' camera_name=1.0\n",
      "\tlaser_object_id='SdPkKCcb4GwSs_dXFeDfKA' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='W5rhCNFFOR-wpcMvRNEM1A' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='YZp0XjCF9MO6a2x7szWEXA' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='Yyu039jUMIJ4gI_2-mTkSg' camera_object_id='6cee0533-b9cd-462e-8a05-d781e8864f16' camera_name=1.0\n",
      "\tlaser_object_id='brLOJzgVMhP_-kdQzIa7ng' camera_object_id='30326915-a157-4c60-9bef-0a188938c998' camera_name=1.0\n",
      "\tlaser_object_id='mOkkhCfy9ezsL1Xpiin0cg' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='qlky7ZEPOYxqaAjh3R6lPQ' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='r1imeuTUWgH_ZJXDYGvC8g' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='sAuz7Nwbj2BM48D9VCq_zQ' camera_object_id='8142dfd0-b30b-4672-9833-3e48ddd7dec8' camera_name=1.0\n",
      "\tlaser_object_id='txvVqORJ6Gcf510DdJvW4Q' camera_object_id='4286a233-4a34-4d99-b214-2d8690e92570' camera_name=1.0\n",
      "\tlaser_object_id='u13bFbFrNUgtlke3hkv95Q' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='0_HBXNo3olLueqYvkPohlg' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='3mqY30kFisxCydiO2pKjPA' camera_object_id='e89cb911-600c-4b1a-a41a-b9681b76aa7d' camera_name=1.0\n",
      "\tlaser_object_id='45vGTk6HpmeCTR2Etiwq8w' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='DMyvJcDBgX_UfZY7i4gQUg' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='FaLjVnzgLbkn0NFfVlonZw' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='JyfDMV88pTVkjurlKpSYsw' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='Kd-ybN2790ngkQSEC0NNkQ' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='LubISPcZqG5jjc-d4fOXBQ' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='Nx3jDnV5BFvG2rNbAk93sw' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='SkvDD99-XNR9FxtiMhbpww' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='dNW3S4yA8s8GmltmAPV8LQ' camera_object_id='24508c28-3154-4b7f-964d-70b3ed7d5a9d' camera_name=1.0\n",
      "\tlaser_object_id='g_YHfVchyJsQkIwc7pzcvw' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='k7sk2VXkecnWsXdCfg3Wig' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='rrONOa8AiwnDsrF8mD8-fw' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='sJlmZW9yFdc8ca--Rhk7mw' camera_object_id='9df71c7e-d3ba-45dc-a107-60646d39dfb6' camera_name=1.0\n",
      "\tlaser_object_id='sJlmZW9yFdc8ca--Rhk7mw' camera_object_id='960d036e-c7ed-4e64-b069-86e114574d77' camera_name=3.0\n",
      "\tlaser_object_id='zW21zQ-BE0degWh8LKLVXw' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='1nDCER_bA9py1ZPpNXecog' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='2SYmRAjI0pCOwp2XYemMBQ' camera_object_id='ba670814-995e-4ade-bc42-58b0a1d8ec8d' camera_name=1.0\n",
      "\tlaser_object_id='2SYmRAjI0pCOwp2XYemMBQ' camera_object_id='ca9be338-79bb-4908-b4ee-5607a21b5b41' camera_name=2.0\n",
      "\tlaser_object_id='8k1Wkk08druqr8A5YTrqFQ' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='AWjsPzPKZ7MTv8Ta3AXBbQ' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='AhVLDKKFO3nP9YBAG8x0pw' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='FF2DYhbJHb6U66o94jP48Q' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='NeHt8l-Xg_tze4fm4Zzhag' camera_object_id='fa0e471f-e5a4-4abc-a528-7be6ed3a1f9e' camera_name=2.0\n",
      "\tlaser_object_id='WrQ9WB5nz7yw3pLq2Sx4JA' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='dWu2dkV959ZVbiXuXYme9A' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='eTLt3z7Tt1__uHa0Pj96uQ' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='hVOvDRfPPYheooNcglGZfw' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='jDO7AFvKzSj9IBX0gjUdVw' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='kWKrXcZMJ7I5K4Z4z9GdSQ' camera_object_id='7f37cfc3-1926-43a1-9af6-109ca0a5c797' camera_name=1.0\n",
      "\tlaser_object_id='oktALDz6ntRSXy5D7zFjEA' camera_object_id='d7539a85-ddfe-4b09-a7c7-13e5f702db6a' camera_name=1.0\n",
      "\tlaser_object_id='pATADVHYfotd4mWyfa9wVw' camera_object_id='7995b22b-fb0d-480d-89a1-c4fd0a37f852' camera_name=2.0\n",
      "\tlaser_object_id='tmWtGvgp0B6MjAE2qZuD9w' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='x3d22mf0934NCWzNdz1CVg' camera_object_id=nan camera_name=nan\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Lazily read DataFrames for all components.\n",
    "association_df = read('camera_to_lidar_box_association')\n",
    "cam_box_df = read('camera_box')\n",
    "cam_img_df = read('camera_image')\n",
    "lidar_box_df = read('lidar_box')\n",
    "lidar_df = read('lidar')\n",
    "lidar_calibration_df = read('lidar_calibration')\n",
    "\n",
    "# Join all DataFrames using matching columns\n",
    "cam_image_w_box_df = v2.merge(cam_box_df, cam_img_df)\n",
    "cam_obj_df = v2.merge(association_df, cam_image_w_box_df)\n",
    "# In this example camera box labels are optional, so we set left_nullable=True.\n",
    "obj_df = v2.merge(cam_obj_df, lidar_box_df, left_nullable=True)\n",
    "# Group lidar sensors (left), group labels and camera images (right) and join.\n",
    "df = v2.merge(lidar_df, obj_df, left_group=True, right_group=True)\n",
    "\n",
    "# Read a single row, which contain data for all data for a single frame.\n",
    "_, row = next(iter(df.iterrows()))\n",
    "# Create all component objects\n",
    "camera_image = v2.CameraImageComponent.from_dict(row)\n",
    "lidar = v2.LiDARComponent.from_dict(row)\n",
    "camera_box = v2.CameraBoxComponent.from_dict(row)\n",
    "lidar_box = v2.LiDARBoxComponent.from_dict(row)\n",
    "lidar_calibration = v2.LiDARCalibrationComponent.from_dict(lidar_calibration_df)\n",
    "\n",
    "print(\n",
    "    f'Found {len(lidar_box.key.laser_object_id)} objects on'\n",
    "    f' {lidar.key.segment_context_name=} {lidar.key.frame_timestamp_micros=}'\n",
    ")\n",
    "for laser_object_id, camera_object_id, camera_name in zip(\n",
    "    lidar_box.key.laser_object_id,\n",
    "    camera_box.key.camera_object_id,\n",
    "    camera_image.key.camera_name,\n",
    "):\n",
    "  print(f'\\t{laser_object_id=} {camera_object_id=} {camera_name=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a00c141d-10a4-4c53-b9ac-93527086f2a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0\n",
      "[array([  64, 2650,    4], dtype=int32), array([200, 600,   4], dtype=int32), array([200, 600,   4], dtype=int32), array([200, 600,   4], dtype=int32), array([200, 600,   4], dtype=int32)]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'tensor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(lidar\u001b[38;5;241m.\u001b[39mrange_image_return1\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# TODO: Eventually should add pixel_pose and frame_pose when mulitple cameras are used\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m points \u001b[38;5;241m=\u001b[39m \u001b[43mv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperception\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlidar_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_range_image_to_point_cloud\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrange_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlidar_calibration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_polar_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/waymo2024_310/lib/python3.10/site-packages/waymo_open_dataset/v2/perception/utils/lidar_utils.py:165\u001b[0m, in \u001b[0;36mconvert_range_image_to_point_cloud\u001b[0;34m(range_image, calibration, pixel_pose, frame_pose, keep_polar_features)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_range_image_to_point_cloud\u001b[39m(\n\u001b[1;32m    143\u001b[0m     range_image: _v2_lidar\u001b[38;5;241m.\u001b[39mRangeImage,\n\u001b[1;32m    144\u001b[0m     calibration: _v2_context\u001b[38;5;241m.\u001b[39mLiDARCalibrationComponent,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    147\u001b[0m     keep_polar_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    148\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m tf\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m    149\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Converts one range image from polar coordinates to point cloud.\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \n\u001b[1;32m    151\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;124;03m      elongation, x, y, z).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 165\u001b[0m   range_image_cartesian \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_range_image_to_cartesian\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m      \u001b[49m\u001b[43mrange_image\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrange_image\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcalibration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcalibration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m      \u001b[49m\u001b[43mpixel_pose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpixel_pose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m      \u001b[49m\u001b[43mframe_pose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe_pose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m      \u001b[49m\u001b[43mkeep_polar_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_polar_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m   range_image_tensor \u001b[38;5;241m=\u001b[39m range_image\u001b[38;5;241m.\u001b[39mtensor\n\u001b[1;32m    173\u001b[0m   range_image_mask \u001b[38;5;241m=\u001b[39m range_image_tensor[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/waymo2024_310/lib/python3.10/site-packages/waymo_open_dataset/v2/perception/utils/lidar_utils.py:85\u001b[0m, in \u001b[0;36mconvert_range_image_to_cartesian\u001b[0;34m(range_image, calibration, pixel_pose, frame_pose, keep_polar_features)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pixel_pose \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     84\u001b[0m   \u001b[38;5;28;01massert\u001b[39;00m frame_pose \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 85\u001b[0m range_image_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mrange_image\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\n\u001b[1;32m     86\u001b[0m extrinsic \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreshape(\n\u001b[1;32m     87\u001b[0m     tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(calibration\u001b[38;5;241m.\u001b[39mextrinsic\u001b[38;5;241m.\u001b[39mtransform),\n\u001b[1;32m     88\u001b[0m     (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m     89\u001b[0m )\n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m# Compute inclinations mapping range image rows to circles in the 3D worlds.\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'tensor'"
     ]
    }
   ],
   "source": [
    "# Get Range image of top lidar\n",
    "range_image = lidar.range_image_return1.values[0]\n",
    "print(range_image[0])\n",
    "print(lidar.range_image_return1.shape)\n",
    "\n",
    "# TODO: Eventually should add pixel_pose and frame_pose when mulitple cameras are used\n",
    "points = v2.perception.utils.lidar_utils.convert_range_image_to_point_cloud(range_image, lidar_calibration, keep_polar_features=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731a3d3e-1747-4e42-83de-94ec62be53c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
