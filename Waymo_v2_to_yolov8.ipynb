{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "640605cf-b96e-4af2-9a8a-7cf3ad702241",
   "metadata": {},
   "source": [
    "# Get point cloud from Waymo v2 format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0800e0a1-7170-490e-9112-872037dcd963",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.10.14\n",
      "2.12.0\n",
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "#@title Initial setup\n",
    "from typing import Optional\n",
    "import warnings\n",
    "# Disable annoying warnings from PyArrow using under the hood.\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from platform import python_version\n",
    "print(python_version())\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "import dask.dataframe as dd\n",
    "from waymo_open_dataset import v2\n",
    "from waymo_open_dataset.utils import  frame_utils\n",
    "\n",
    "\n",
    "# Path to the directory with all components\n",
    "dataset_dir = '/home/wod_v2/src/data/perception_2.0.0/training'\n",
    "\n",
    "context_name = '10023947602400723454_1120_000_1140_000'\n",
    "\n",
    "def read(tag: str) -> dd.DataFrame:\n",
    "  \"\"\"Creates a Dask DataFrame for the component specified by its tag.\"\"\"\n",
    "  paths = tf.io.gfile.glob(f'{dataset_dir}/{tag}/{context_name}.parquet')\n",
    "  return dd.read_parquet(paths)\n",
    "\n",
    "\n",
    "\n",
    "# Lazily read DataFrames for all components.\n",
    "association_df = read('camera_to_lidar_box_association')\n",
    "cam_box_df = read('camera_box')\n",
    "cam_img_df = read('camera_image')\n",
    "lidar_box_df = read('lidar_box')\n",
    "lidar_df = read('lidar')\n",
    "lidar_calibration_df = read('lidar_calibration')\n",
    "\n",
    "association_df = association_df[association_df['key.camera_name'] == 1]\n",
    "cam_box_df = cam_box_df[cam_box_df['key.camera_name'] == 1]\n",
    "cam_img_df = cam_img_df[cam_img_df['key.camera_name'] == 1].compute()\n",
    "lidar_df = lidar_df[lidar_df['key.laser_name'] == 1]\n",
    "lidar_calibration_df = lidar_calibration_df[lidar_calibration_df['key.laser_name'] == 1].compute()\n",
    "\n",
    "# Join all DataFrames using matching columns\n",
    "cam_image_w_box_df = v2.merge(cam_box_df, cam_img_df)\n",
    "cam_obj_df = v2.merge(association_df, cam_image_w_box_df)\n",
    "# In this example camera box labels are optional, so we set left_nullable=True.\n",
    "obj_df = v2.merge(cam_obj_df, lidar_box_df, left_nullable=True)\n",
    "# Group lidar sensors (left), group labels and camera images (right) and join.\n",
    "df = v2.merge(lidar_df, obj_df, left_group=True, right_group=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "132906ba-be4f-41a0-b888-3b5817ef53cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 78 objects on lidar.key.segment_context_name='10023947602400723454_1120_000_1140_000' lidar.key.frame_timestamp_micros=1552440195362591\n",
      "\tlaser_object_id='-U88NMYnocLWCh6iqZwj1g' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='0VCoeT-jjrIfzTCsOWz20A' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='0_HBXNo3olLueqYvkPohlg' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='1nDCER_bA9py1ZPpNXecog' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='2-A6zakvKX2opVnyx9gplQ' camera_object_id='a6f937a6-7ea8-4393-b636-e0560e699856' camera_name=1.0\n",
      "\tlaser_object_id='2OYKagQRfCdaOXgU5RkMBA' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='2SYmRAjI0pCOwp2XYemMBQ' camera_object_id='ba670814-995e-4ade-bc42-58b0a1d8ec8d' camera_name=1.0\n",
      "\tlaser_object_id='3083QteOhZ_vSpxmP0XK-Q' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='38Np8bwqcvw9KkrH3xHfpg' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='3I9vmrICjjnWtavq3ysJrQ' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='3mqY30kFisxCydiO2pKjPA' camera_object_id='e89cb911-600c-4b1a-a41a-b9681b76aa7d' camera_name=1.0\n",
      "\tlaser_object_id='45vGTk6HpmeCTR2Etiwq8w' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='63vjcxiQGxy6SmQ94yX-FQ' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='81faaqjwezt3wc0ZN-1N0g' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='8IZ7fkXm0FDeUdEuJAqSlA' camera_object_id='260f57c0-787d-4f36-bfe9-64ca9828448f' camera_name=1.0\n",
      "\tlaser_object_id='8k1Wkk08druqr8A5YTrqFQ' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='A4kzX4tBck4XcFuUOPA6Lg' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='AWjsPzPKZ7MTv8Ta3AXBbQ' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='AhVLDKKFO3nP9YBAG8x0pw' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='CB379cbEIKwW6eAs4wK6mw' camera_object_id='baae00a2-cacd-43c9-9d83-0932920c987e' camera_name=1.0\n",
      "\tlaser_object_id='DMyvJcDBgX_UfZY7i4gQUg' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='EKH1nF9LYmAF7RP2zcpTAw' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='FF2DYhbJHb6U66o94jP48Q' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='FaLjVnzgLbkn0NFfVlonZw' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='GZswbdmDQZSe88ajnioK_g' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='Iv3M96stRJ3JE-umZR0uVA' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='JyfDMV88pTVkjurlKpSYsw' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='Kd-ybN2790ngkQSEC0NNkQ' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='L5HBM5tSKtNA4qHegDQk8Q' camera_object_id='4b9a9206-fbf1-4d45-8765-197759100bd6' camera_name=1.0\n",
      "\tlaser_object_id='LubISPcZqG5jjc-d4fOXBQ' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='MGw5mrKnm4f98o1li921HQ' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='NeHt8l-Xg_tze4fm4Zzhag' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='Nx3jDnV5BFvG2rNbAk93sw' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='OTxlocnBbws-LpK8i2X10w' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='OkBzhxzagapiYam_4NK-9A' camera_object_id='eff781d6-b34f-400b-95ad-b960fa0270d8' camera_name=1.0\n",
      "\tlaser_object_id='PrS_b18HNPEbxJ9IAYW2BQ' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='SdPkKCcb4GwSs_dXFeDfKA' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='SkvDD99-XNR9FxtiMhbpww' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='W5rhCNFFOR-wpcMvRNEM1A' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='WrQ9WB5nz7yw3pLq2Sx4JA' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='YTw2k0_-8UqolJn4WQRc2g' camera_object_id='699b6cb3-afc1-469f-8ac9-40978aeb511b' camera_name=1.0\n",
      "\tlaser_object_id='YZp0XjCF9MO6a2x7szWEXA' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='Yyu039jUMIJ4gI_2-mTkSg' camera_object_id='6cee0533-b9cd-462e-8a05-d781e8864f16' camera_name=1.0\n",
      "\tlaser_object_id='ZyK_iICxQsEYdJLxMFTw7w' camera_object_id='08b1e19e-b912-4963-a7bb-55e138bbc25e' camera_name=1.0\n",
      "\tlaser_object_id='aZNY65GX0cPUkxaWoiYiFA' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='brLOJzgVMhP_-kdQzIa7ng' camera_object_id='30326915-a157-4c60-9bef-0a188938c998' camera_name=1.0\n",
      "\tlaser_object_id='dNW3S4yA8s8GmltmAPV8LQ' camera_object_id='24508c28-3154-4b7f-964d-70b3ed7d5a9d' camera_name=1.0\n",
      "\tlaser_object_id='dWu2dkV959ZVbiXuXYme9A' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='eTLt3z7Tt1__uHa0Pj96uQ' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='g_YHfVchyJsQkIwc7pzcvw' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='hVOvDRfPPYheooNcglGZfw' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='hhuZm4IrFKySygbA_3k80w' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='iYoNqzfcHozgqJVHl7Yxnw' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='jDO7AFvKzSj9IBX0gjUdVw' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='jYdxjpZOYqJdSiBQI133Fw' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='k7sk2VXkecnWsXdCfg3Wig' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='kWKrXcZMJ7I5K4Z4z9GdSQ' camera_object_id='7f37cfc3-1926-43a1-9af6-109ca0a5c797' camera_name=1.0\n",
      "\tlaser_object_id='l9f--u5kPKABASTzvy9Nug' camera_object_id='d4a7521f-1659-4ef3-a5ce-dc0811a223f6' camera_name=1.0\n",
      "\tlaser_object_id='mOkkhCfy9ezsL1Xpiin0cg' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='oktALDz6ntRSXy5D7zFjEA' camera_object_id='d7539a85-ddfe-4b09-a7c7-13e5f702db6a' camera_name=1.0\n",
      "\tlaser_object_id='oq32CII6BSHT6k4uzf5XrA' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='pATADVHYfotd4mWyfa9wVw' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='pJ3fmc4NHVFkhDPgGBtS4Q' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='qlky7ZEPOYxqaAjh3R6lPQ' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='r1imeuTUWgH_ZJXDYGvC8g' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='rM0XsOkipsd4-TUUQ5ncsQ' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='rrONOa8AiwnDsrF8mD8-fw' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='sAuz7Nwbj2BM48D9VCq_zQ' camera_object_id='8142dfd0-b30b-4672-9833-3e48ddd7dec8' camera_name=1.0\n",
      "\tlaser_object_id='sJlmZW9yFdc8ca--Rhk7mw' camera_object_id='9df71c7e-d3ba-45dc-a107-60646d39dfb6' camera_name=1.0\n",
      "\tlaser_object_id='t9E-elYgX_LpXadnao0H3Q' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='tmWtGvgp0B6MjAE2qZuD9w' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='txvVqORJ6Gcf510DdJvW4Q' camera_object_id='4286a233-4a34-4d99-b214-2d8690e92570' camera_name=1.0\n",
      "\tlaser_object_id='u13bFbFrNUgtlke3hkv95Q' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='uTQJwYsr8nw8M5kF2ELaiA' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='wO7bCMlAPPxIZSpihCgJBw' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='wcj6Uo3otoyeYSL_80w-Rw' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='x3d22mf0934NCWzNdz1CVg' camera_object_id=nan camera_name=nan\n",
      "\tlaser_object_id='zW21zQ-BE0degWh8LKLVXw' camera_object_id=nan camera_name=nan\n"
     ]
    }
   ],
   "source": [
    "# Read a single row, which contain data for all data for a single frame.\n",
    "_, row = next(iter(df.iterrows()))\n",
    "# Create all component objects\n",
    "camera_image = v2.CameraImageComponent.from_dict(row)\n",
    "lidar = v2.LiDARComponent.from_dict(row)\n",
    "camera_box = v2.CameraBoxComponent.from_dict(row)\n",
    "lidar_box = v2.LiDARBoxComponent.from_dict(row)\n",
    "lidar_calibration = v2.LiDARCalibrationComponent.from_dict(lidar_calibration_df)\n",
    "\n",
    "print(\n",
    "    f'Found {len(lidar_box.key.laser_object_id)} objects on'\n",
    "    f' {lidar.key.segment_context_name=} {lidar.key.frame_timestamp_micros=}'\n",
    ")\n",
    "for laser_object_id, camera_object_id, camera_name in zip(\n",
    "    lidar_box.key.laser_object_id,\n",
    "    camera_box.key.camera_object_id,\n",
    "    camera_image.key.camera_name,\n",
    "):\n",
    "  print(f'\\t{laser_object_id=} {camera_object_id=} {camera_name=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a00c141d-10a4-4c53-b9ac-93527086f2a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RangeImage(values=array([-1., -1., -1., ..., -1., -1., -1.], dtype=float32), shape=array([  64, 2650,    4], dtype=int32))\n",
      "<class 'numpy.ndarray'>\n",
      "[  64 2650    4]\n",
      "[-8.50486534e-01 -5.25981865e-01 -3.96644352e-03  1.43000000e+00\n",
      "  5.25971210e-01 -8.50495357e-01  3.45458508e-03  0.00000000e+00\n",
      " -5.19049090e-03  8.51842992e-04  9.99986166e-01  2.18400000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]\n",
      "<class 'waymo_open_dataset.v2.column_types.Transform'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'waymo_open_dataset.v2.perception.context.LiDARCalibrationComponent'>\n"
     ]
    }
   ],
   "source": [
    "# Get Range image of top lidar\n",
    "range_image_orig = lidar.range_image_return1\n",
    "\n",
    "range_image = v2.perception.lidar.RangeImage(lidar.range_image_return1.values[0], lidar.range_image_return1.shape[0])\n",
    "\n",
    "print(range_image)\n",
    "print(type(range_image.values))\n",
    "print(range_image.shape)\n",
    "\n",
    "temp_tfm = v2.column_types.Transform\n",
    "temp_tfm.transform = lidar_calibration.extrinsic.transform.tolist()[0]\n",
    "temp_bic = v2.perception.context.BeamInclination\n",
    "temp_bic.min = lidar_calibration.beam_inclination.min\n",
    "temp_bic.max = lidar_calibration.beam_inclination.max\n",
    "temp_bic.values = lidar_calibration.beam_inclination.values.tolist()[0]\n",
    "\n",
    "lc2 = v2.perception.context.LiDARCalibrationComponent(lidar_calibration.key, temp_tfm, temp_bic)\n",
    "\n",
    "print(lidar_calibration.extrinsic.transform.tolist()[0])\n",
    "print(type(lidar_calibration.extrinsic))\n",
    "print(type(lidar_calibration.extrinsic.transform))\n",
    "print(type(lidar_calibration_df))\n",
    "print(type(lidar_calibration))\n",
    "# extrinsic = tf.convert_to_tensor(lidar_calibration.extrinsic.transform)\n",
    "\n",
    "# TODO: Eventually should add pixel_pose and frame_pose when mulitple cameras are used\n",
    "points = v2.perception.utils.lidar_utils.convert_range_image_to_point_cloud(range_image, lc2, keep_polar_features=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abc0913-819c-4564-bd8d-295d1a0b1e7d",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f5244846-72e6-4a31-a905-46f55ca66831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  64 2650    4]\n",
      "387998\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) :-1: error: (-5:Bad argument) in function 'imshow'\n> Overload resolution failed:\n>  - mat data type = |S387998 is not supported\n>  - Expected Ptr<cv::cuda::GpuMat> for argument 'mat'\n>  - Expected Ptr<cv::UMat> for argument 'mat'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(camera_image\u001b[38;5;241m.\u001b[39mimage[\u001b[38;5;241m4\u001b[39m]))\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m (\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m---> 12\u001b[0m     \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m10\u001b[39m) \u001b[38;5;241m&\u001b[39m \u001b[38;5;241m0xFF\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m27\u001b[39m:\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.10.0) :-1: error: (-5:Bad argument) in function 'imshow'\n> Overload resolution failed:\n>  - mat data type = |S387998 is not supported\n>  - Expected Ptr<cv::cuda::GpuMat> for argument 'mat'\n>  - Expected Ptr<cv::UMat> for argument 'mat'\n"
     ]
    }
   ],
   "source": [
    "print(range_image.shape)\n",
    "ri = np.reshape(range_image.values, range_image.shape)\n",
    "while (1):\n",
    "    cv2.imshow('range_image', ri)\n",
    "    if cv2.waitKey(10) & 0xFF == 27:\n",
    "        break\n",
    "cv2.destroyAllWindows\n",
    "\n",
    "img = np.array(camera_image.image[4])\n",
    "print(len(camera_image.image[4]))\n",
    "while (1):\n",
    "    cv2.imshow('image', img)\n",
    "    if cv2.waitKey(10) & 0xFF == 27:\n",
    "        break\n",
    "cv2.destroyAllWindows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60bcb2b5-dc02-4283-aeab-cf3cb1f266fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(149796, 6)\n",
      "tf.Tensor([ 4.752197   4.3479753  8.619505  ... -1.8297869 -1.8156391 -1.7855257], shape=(149796,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(points.shape)\n",
    "print(points[:,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc94b25-7997-4bcc-b79d-a88cb2e6294b",
   "metadata": {},
   "source": [
    "# Pipeline to yolo bev format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c16f27cf-4f30-4c9d-b2e0-bab6a6637ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# create birds-eye view of lidar data\n",
    "def bev_from_pcl(lidar_pcl, configs, viz=False, verbose=False):\n",
    "    # remove lidar points outside detection area and with too low reflectivity\n",
    "    mask = np.where((lidar_pcl[:, POINTCLOUD_X_INDEX] >= configs['lim_x'][0]) & (lidar_pcl[:, POINTCLOUD_X_INDEX] <= configs['lim_x'][1]) &\n",
    "                    (lidar_pcl[:, POINTCLOUD_Y_INDEX] >= configs['lim_y'][0]) & (lidar_pcl[:, POINTCLOUD_Y_INDEX] <= configs['lim_y'][1]))# &\n",
    "                    #(lidar_pcl[:, POINTCLOUD_Z_INDEX] >= configs['lim_z'][0]) & (lidar_pcl[:, POINTCLOUD_Z_INDEX] <= configs['lim_z'][1]))\n",
    "    lidar_pcl = lidar_pcl[mask]\n",
    "    \n",
    "    # shift level of ground plane to avoid flipping from 0 to 255 for neighboring pixels\n",
    "    lidar_pcl[:, POINTCLOUD_Z_INDEX] = lidar_pcl[:, POINTCLOUD_Z_INDEX] - configs['lim_z'][0]  \n",
    "\n",
    "    if verbose:\n",
    "        print(lidar_pcl[0,:])\n",
    "        print('Min and max height, %f, %f' %(np.min(lidar_pcl[:,2]), np.max(lidar_pcl[:,2])))\n",
    "\n",
    "    # convert sensor coordinates to bev-map coordinates (center is bottom-middle)\n",
    "\n",
    "    ## step 1 : compute bev-map discretization by dividing x-range by the bev-image height (see configs)\n",
    "    delta_x_rw_meters = configs['lim_x'][1] - configs['lim_x'][0]\n",
    "    delta_y_rw_meters = configs['lim_y'][1] - configs['lim_y'][0]\n",
    "    meters_pixel_x = delta_x_rw_meters / configs['bev_height']\n",
    "    meters_pixel_y = delta_y_rw_meters / configs['bev_width']\n",
    "\n",
    "    ## step 2 : create a copy of the lidar pcl and transform all metrix x-coordinates into bev-image coordinates  \n",
    "    lidar_pcl_copy = np.copy(lidar_pcl)\n",
    "    lidar_pcl_copy[:, POINTCLOUD_X_INDEX] = np.int_(np.floor(lidar_pcl_copy[:, POINTCLOUD_X_INDEX] / meters_pixel_x))  \n",
    "\n",
    "    # step 3 : perform the same operation as in step 2 for the y-coordinates but make sure that no negative bev-coordinates occur\n",
    "    lidar_pcl_copy[:, POINTCLOUD_Y_INDEX] = np.int_(np.floor(lidar_pcl_copy[:, POINTCLOUD_Y_INDEX] / meters_pixel_y) + (configs['bev_width'] + 1) / 2)\n",
    "\n",
    "    # step 4 : visualize point-cloud using the function show_pcl from a previous task\n",
    "    # if viz:\n",
    "    #     show_pcl(lidar_pcl_copy)\n",
    "   \n",
    "   \n",
    "    # Compute intensity layer of the BEV map\n",
    "\n",
    "    ## step 1 : create a numpy array filled with zeros which has the same dimensions as the BEV map\n",
    "    intensity_map = np.zeros((configs['bev_height'] + 1, configs['bev_width'] + 1))\n",
    "\n",
    "    # step 2 : re-arrange elements in lidar_pcl_cpy by sorting first by x, then y, then -z (use numpy.lexsort)\n",
    "    lidar_pcl_copy[lidar_pcl_copy[:, POINTCLOUD_INTENSITY] > 1.0, POINTCLOUD_INTENSITY] = 1.0\n",
    "    index_vector_int = np.lexsort((-lidar_pcl_copy[:, POINTCLOUD_INTENSITY], lidar_pcl_copy[:, POINTCLOUD_Y_INDEX], lidar_pcl_copy[:, POINTCLOUD_X_INDEX]))\n",
    "    lidar_pcl_top = lidar_pcl_copy[index_vector_int]\n",
    "\n",
    "    ## step 3 : extract all points with identical x and y such that only the top-most z-coordinate is kept (use numpy.unique)\n",
    "    ##          also, store the number of points per x,y-cell in a variable named \"counts\" for use in the next task\n",
    "    _, idx_int_unique, counts = np.unique(lidar_pcl_top[:, POINTCLOUD_X_INDEX:POINTCLOUD_Z_INDEX], return_index=True, return_inverse=False, return_counts=True, axis=0)\n",
    "    lidar_pcl_top = lidar_pcl_top[idx_int_unique]\n",
    "\n",
    "    intensity_map = np.zeros((configs['bev_height'] + 1, configs['bev_width'] + 1))\n",
    "    \n",
    "    ## step 4 : assign the intensity value of each unique entry in lidar_pcl_top to the intensity map \n",
    "    ##          make sure that the intensity is scaled in such a way that objects of interest (e.g. vehicles) are clearly visible    \n",
    "    ##          also, make sure that the influence of outliers is mitigated by normalizing intensity on the difference between the max. and min. value within the point cloud\n",
    "    intensity_map[np.int_(lidar_pcl_top[:, POINTCLOUD_X_INDEX]), np.int_(lidar_pcl_top[:, POINTCLOUD_Y_INDEX])] = lidar_pcl_top[:, POINTCLOUD_INTENSITY] / (np.amax(lidar_pcl_top[:, POINTCLOUD_INTENSITY]) - np.amin(lidar_pcl_top[:, POINTCLOUD_INTENSITY]))\n",
    "\n",
    "    # if viz:\n",
    "    #     analyze({'before': lidar_pcl_top_copy, 'after': lidar_pcl_top_copy_post}, title='Intensity Distribution', nqp=False)\n",
    "\n",
    "    ## step 5 : temporarily visualize the intensity map using OpenCV to make sure that vehicles separate well from the background\n",
    "    img_intensity = intensity_map * 255\n",
    "    img_intensity = img_intensity.astype(np.uint8)\n",
    "    if viz:\n",
    "        while (1):\n",
    "            cv2.imshow('img_intensity', img_intensity)\n",
    "            if cv2.waitKey(10) & 0xFF == 27:\n",
    "                break\n",
    "        cv2.destroyAllWindows\n",
    "\n",
    "   \n",
    "\n",
    "    # Compute height layer of the BEV map\n",
    "\n",
    "    ## step 1 : create a numpy array filled with zeros which has the same dimensions as the BEV map\n",
    "    height_map = np.zeros((configs['bev_height'] + 1, configs['bev_width'] + 1))\n",
    "\n",
    "    ## step 2 : assign the height value of each unique entry in lidar_top_pcl to the height map\n",
    "    ##          make sure that each entry is normalized on the difference between the upper and lower height defined in the config file\n",
    "    ##          use the lidar_pcl_top data structure from the previous task to access the pixels of the height_map\n",
    "    # _, idx_height_unique, counts = np.unique(lidar_pcl_top[:, 0:2], return_index=True, return_inverse=False, return_counts=True, axis=0)\n",
    "    # lidar_pcl_hei = lidar_pcl_top[idx_height_unique]\n",
    "    height_map[np.int_(lidar_pcl_top[:, POINTCLOUD_X_INDEX]), np.int_(lidar_pcl_top[:, POINTCLOUD_Y_INDEX])] = lidar_pcl_top[:, POINTCLOUD_Z_INDEX] / float(np.abs(configs['lim_z'][1] - configs['lim_z'][0]))\n",
    "\n",
    "    ## step 3 : temporarily visualize the intensity map using OpenCV to make sure that vehicles separate well from the background\n",
    "    img_height = height_map * 256\n",
    "    img_height = img_height.astype(np.uint8)\n",
    "    if viz:\n",
    "        while (1):\n",
    "            cv2.imshow('img_height', img_height)\n",
    "            if cv2.waitKey(10) & 0xFF == 27:\n",
    "                break\n",
    "        cv2.destroyAllWindows\n",
    "\n",
    "    #######\n",
    "    ####### ID_S2_EX3 END #######       \n",
    "\n",
    "    # TODO remove after implementing all of the above steps\n",
    "    # lidar_pcl_cpy = []\n",
    "    # lidar_pcl_top = []\n",
    "    # height_map = []\n",
    "    # intensity_map = []\n",
    "\n",
    "    # Compute density layer of the BEV map\n",
    "\n",
    "\n",
    "    density_map = np.zeros((configs['bev_height'] + 1, configs['bev_width'] + 1))\n",
    "    _, _, counts = np.unique(lidar_pcl_copy[:, POINTCLOUD_X_INDEX:POINTCLOUD_Z_INDEX], axis=0, return_index=True, return_counts=True)\n",
    "    normalizedCounts = np.minimum(1.0, np.log(counts + 1) / np.log(64)) \n",
    "    density_map[np.int_(lidar_pcl_top[:, POINTCLOUD_X_INDEX]), np.int_(lidar_pcl_top[:, POINTCLOUD_Y_INDEX])] = normalizedCounts\n",
    "\n",
    "    \n",
    "    if viz:\n",
    "        while (1):\n",
    "            cv2.imshow('density map', density_map)\n",
    "            if cv2.waitKey(10) & 0xFF == 27:\n",
    "                break\n",
    "        cv2.destroyAllWindows\n",
    "    \n",
    "    # assemble 3-channel bev-map from individual maps\n",
    "    bev_map = np.zeros((3, configs['bev_height'], configs['bev_width']))\n",
    "    bev_map[2, :, :] = density_map[:configs['bev_height'], :configs['bev_width']]  # r_map\n",
    "    bev_map[1, :, :] = height_map[:configs['bev_height'], :configs['bev_width']]  # g_map\n",
    "    bev_map[0, :, :] = intensity_map[:configs['bev_height'], :configs['bev_width']]  # b_map\n",
    "    \n",
    "    bev_map_cpy = np.zeros((configs['bev_height'], configs['bev_width'], 3))\n",
    "    bev_map_cpy[:, :, 2] = density_map[:configs['bev_height'], :configs['bev_width']] /  density_map.max() # r_map\n",
    "    bev_map_cpy[:, :, 1] = height_map[:configs['bev_height'], :configs['bev_width']] / height_map.max() # g_map\n",
    "    bev_map_cpy[:, :, 0] = intensity_map[:configs['bev_height'], :configs['bev_width']] / intensity_map.max() # b_map\n",
    "\n",
    "    # expand dimension of bev_map before converting into a tensor\n",
    "    s1, s2, s3 = bev_map.shape\n",
    "    bev_maps = np.zeros((1, s1, s2, s3))\n",
    "    bev_maps[0] = bev_map\n",
    "\n",
    "    if viz:\n",
    "        print(bev_map_cpy.shape)\n",
    "        # bev_map_cpy = np.reshape(bev_map, (bev_map.shape[1], bev_map.shape[2], bev_map.shape[0]))\n",
    "        print( intensity_map.max(), height_map.max(), density_map.max())\n",
    "        while (1):\n",
    "            cv2.imshow('bev_map', bev_map_cpy)\n",
    "            if cv2.waitKey(10) & 0xFF == 27:\n",
    "                break\n",
    "        cv2.destroyAllWindows\n",
    "    # bev_maps = torch.from_numpy(bev_maps)  # create tensor from birds-eye view\n",
    "    # input_bev_maps = bev_maps.to(configs[device], non_blocking=True).float()\n",
    "\n",
    "    # show_bev(input_bev_maps, configs)\n",
    "\n",
    "    return bev_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4d76214c-95b7-4cf5-8198-52840a10f504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(640, 480, 3)\n",
      "1.0002576112747192 1.502228856086731 1.0\n"
     ]
    }
   ],
   "source": [
    "configs = {}\n",
    "configs['lim_x'] = [0,53]\n",
    "configs['lim_y'] = [-20,20]\n",
    "configs['lim_z'] = [-3.1, 2]\n",
    "configs['lim_r'] = [0, 1.0]\n",
    "configs['bev_height'] = 640\n",
    "configs['bev_width'] = 480\n",
    "\n",
    "# points_xyzl = points[:, :4]\n",
    "# points_xyzl[:, :2] = points[:, 3:5]\n",
    "# points_xyzl[:, 3] = points[:, 1]\n",
    "POINTCLOUD_X_INDEX = 3\n",
    "POINTCLOUD_Y_INDEX = 4\n",
    "POINTCLOUD_Z_INDEX = 5\n",
    "POINTCLOUD_INTENSITY = 1\n",
    "# print(points_xyzl[:, POINTCLOUD_Z_INDEX].min(), ' ', points_xyzl[:, POINTCLOUD_Z_INDEX].max())\n",
    "\n",
    "points_cpu = points.numpy()\n",
    "bev_map = bev_from_pcl(points_cpu, configs, viz=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "79297ac3-56f3-43e6-bd28-79bca37b12a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_to_pixel(box):\n",
    "    w_ = configs['bev_height'] / (configs['lim_x'][1] - configs['lim_x'][0])\n",
    "    l_ = configs['bev_width'] / (configs['lim_y'][1] - configs['lim_y'][0])\n",
    "    x1 = (box[0] - box[2] / 2 - configs['lim_x'][0]) * w_\n",
    "    x2 = (box[0] + box[2] / 2 - configs['lim_x'][0]) * w_\n",
    "    y1 = (box[1] - box[3] / 2 - configs['lim_y'][0]) * l_\n",
    "    y2 = (box[1] + box[3] / 2 - configs['lim_y'][0]) * l_\n",
    "    return [x1,y1 ,x2 ,y2 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "04bb64b2-2a50-4324-b0b4-7494628c8c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "[-20.86353529   3.07001304   4.2105113    1.84526304]\n",
      "(39, 4)\n",
      "(640, 480)\n",
      "(640, 480, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function destroyAllWindows>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get box\n",
    "print(type(lidar_box.box.center.x))\n",
    "\n",
    "POINTCLOUD_X_INDEX = 0\n",
    "POINTCLOUD_Y_INDEX = 1\n",
    "lidar_box_masked = np.transpose(np.array([np.array(lidar_box.box.center.x), np.array(lidar_box.box.center.y), np.array(lidar_box.box.size.x), np.array(lidar_box.box.size.y)]))\n",
    "print(lidar_box_masked[0, :])\n",
    "mask = np.where((lidar_box_masked[:, POINTCLOUD_X_INDEX] >= configs['lim_x'][0]) & (lidar_box_masked[:, POINTCLOUD_X_INDEX] <= configs['lim_x'][1]) &\n",
    "                (lidar_box_masked[:, POINTCLOUD_Y_INDEX] >= configs['lim_y'][0]) & (lidar_box_masked[:, POINTCLOUD_Y_INDEX] <= configs['lim_y'][1]))# &\n",
    "                #(lidar_pcl[:, POINTCLOUD_Z_INDEX] >= configs['lim_z'][0]) & (lidar_pcl[:, POINTCLOUD_Z_INDEX] <= configs['lim_z'][1]))\n",
    "lidar_box_masked = lidar_box_masked[mask]\n",
    "print(lidar_box_masked.shape)\n",
    "print(bev_map[0,0,:,:].shape)\n",
    "bev_map_img = bev_map[0].copy() \n",
    "bev_map_img = bev_map_img.transpose(1,2,0).astype(np.uint8)\n",
    "print(bev_map_img.shape)\n",
    "\n",
    "bev_map_cpy = np.zeros((configs['bev_height'], configs['bev_width'], 3))\n",
    "bev_map_cpy[:, :, 2] = bev_map[0,2,:configs['bev_height'], :configs['bev_width']] /  bev_map[0,2,:,:].max() # r_map\n",
    "bev_map_cpy[:, :, 1] = bev_map[0,1,:configs['bev_height'], :configs['bev_width']] / bev_map[0,1,:,:].max() # g_map\n",
    "bev_map_cpy[:, :, 0] = bev_map[0,0,:configs['bev_height'], :configs['bev_width']] / bev_map[0,0,:,:].max() # b_map\n",
    "\n",
    "\n",
    "for box in lidar_box_masked:\n",
    "    # print(\"x: \", box[0], \" y: \", box[1], \" w: \", box[2], \" l: \", box[3])\n",
    "    xyxy = distance_to_pixel(box)\n",
    "    # print(\"x1: \", xyxy[0], \" y1: \", xyxy[1], \" x2: \", xyxy[2], \" y2: \", xyxy[3])\n",
    "    cv2.rectangle(bev_map_cpy, (int(xyxy[1]), int(xyxy[0])), (int(xyxy[3]), int(xyxy[2])), thickness=2, color=(100,100,0))\n",
    "    # cv2.putText(bev_map, names[int(cls)], (int(xyxy[0]), int(xyxy[1]) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color=(100,100,0), thickness=2)\n",
    "\n",
    "while (1):                \n",
    "    cv2.imshow('bev_map2', bev_map_cpy)\n",
    "    if cv2.waitKey(10) & 0xFF == 27:\n",
    "        break\n",
    "cv2.destroyAllWindows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51ccc36-bb95-4782-919f-5ebfab247366",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Project detections into bev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101ceadb-e70c-44c6-99fe-82d9f87a3118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# project detected bounding boxes into birds-eye view\n",
    "def project_detections_into_bev(bev_map, detections, configs, color=[]):\n",
    "    for row in detections:\n",
    "        # extract detection\n",
    "        _id, _x, _y, _z, _h, _w, _l, _yaw = row\n",
    "\n",
    "        # convert from metric into pixel coordinates\n",
    "        x = (_y - configs.lim_y[0]) / (configs.lim_y[1] - configs.lim_y[0]) * configs.bev_width\n",
    "        y = (_x - configs.lim_x[0]) / (configs.lim_x[1] - configs.lim_x[0]) * configs.bev_height\n",
    "        z = _z - configs.lim_z[0]\n",
    "        w = _w / (configs.lim_y[1] - configs.lim_y[0]) * configs.bev_width\n",
    "        l = _l / (configs.lim_x[1] - configs.lim_x[0]) * configs.bev_height\n",
    "        yaw = -_yaw\n",
    "\n",
    "        # draw object bounding box into birds-eye view\n",
    "        if not color:\n",
    "            color = configs.obj_colors[int(_id)]\n",
    "        \n",
    "        # get object corners within bev image\n",
    "        bev_corners = np.zeros((4, 2), dtype=np.float32)\n",
    "        cos_yaw = np.cos(yaw)\n",
    "        sin_yaw = np.sin(yaw)\n",
    "        bev_corners[0, 0] = x - w / 2 * cos_yaw - l / 2 * sin_yaw # front left\n",
    "        bev_corners[0, 1] = y - w / 2 * sin_yaw + l / 2 * cos_yaw \n",
    "        bev_corners[1, 0] = x - w / 2 * cos_yaw + l / 2 * sin_yaw # rear left\n",
    "        bev_corners[1, 1] = y - w / 2 * sin_yaw - l / 2 * cos_yaw\n",
    "        bev_corners[2, 0] = x + w / 2 * cos_yaw + l / 2 * sin_yaw # rear right\n",
    "        bev_corners[2, 1] = y + w / 2 * sin_yaw - l / 2 * cos_yaw\n",
    "        bev_corners[3, 0] = x + w / 2 * cos_yaw - l / 2 * sin_yaw # front right\n",
    "        bev_corners[3, 1] = y + w / 2 * sin_yaw + l / 2 * cos_yaw\n",
    "        \n",
    "        # draw object as box\n",
    "        corners_int = bev_corners.reshape(-1, 1, 2).astype(int)\n",
    "        cv2.polylines(bev_map, [corners_int], True, color, 2)\n",
    "\n",
    "        # draw colored line to identify object front\n",
    "        corners_int = bev_corners.reshape(-1, 2)\n",
    "        cv2.line(bev_map, (int(corners_int[0, 0]), int(corners_int[0, 1])), (int(corners_int[3, 0]), int(corners_int[3, 1])), (255, 255, 0), 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4886b269-a6f0-4314-b555-5cb25b9fd1c8",
   "metadata": {},
   "source": [
    "### Add boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fc004b-45c7-4d2d-8900-3bb84135f11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addBoxes(results):\n",
    "    for result in results:\n",
    "        boxes = result.boxes\n",
    "        probs = result.probs\n",
    "        img = result.orig_img\n",
    "        classes = boxes.cls.cpu().numpy()\n",
    "        names = result.names\n",
    "        # print(boxes, ', prob:')\n",
    "        for i, xyxy in enumerate(boxes.xyxy.cpu().numpy()):\n",
    "            # print(xyxy[0])\n",
    "            cls = classes[i]\n",
    "\n",
    "            if int(cls) in colors_map:\n",
    "                color = colors_map[cls]\n",
    "                cv2.rectangle(img, (int(xyxy[0]), int(xyxy[1])), (int(xyxy[2]), int(xyxy[3])), thickness=2, color=color)\n",
    "                cv2.putText(img, names[int(cls)], (int(xyxy[0]), int(xyxy[1]) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color=color, thickness=2)\n",
    "            \n",
    "    cv2.imshow('Camera and detected objects', img)\n",
    "    cv2.waitKey(0) \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6372a9be-480b-4322-a35b-6f0646e95a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility for fixing \n",
    "range_image = v2.perception.lidar.RangeImage(lidar.range_image_return1.values[0], lidar.range_image_return1.shape[0])\n",
    "\n",
    "print(range_image.values)\n",
    "print(type(range_image))\n",
    "print(type(range_image_orig))\n",
    "rit = range_image.tensor\n",
    "print(rit)\n",
    "print(type(rit))\n",
    "# tf.convert_to_tensor(lidar_calibration.extrinsic.transform.tolist())\n",
    "\n",
    "points = v2.perception.utils.lidar_utils.convert_range_image_to_point_cloud(range_image, lc2, keep_polar_features=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae0de08e-9270-4bc3-bf26-48ef4e0c3368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "key.segment_context_name                                                             10023947602400723454_1120_000_1140_000\n",
       "key.frame_timestamp_micros                                                                                 1552440195362591\n",
       "key.laser_name                                                                                                          [1]\n",
       "[LiDARComponent].range_image_return1.values                               [[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1...\n",
       "[LiDARComponent].range_image_return1.shape                                                                  [[64, 2650, 4]]\n",
       "[LiDARComponent].range_image_return2.values                               [[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1...\n",
       "[LiDARComponent].range_image_return2.shape                                                                  [[64, 2650, 4]]\n",
       "key.camera_name                                                           [nan, nan, nan, nan, 1.0, nan, 1.0, nan, nan, ...\n",
       "key.camera_object_id                                                      [nan, nan, nan, nan, a6f937a6-7ea8-4393-b636-e...\n",
       "key.laser_object_id                                                       [-U88NMYnocLWCh6iqZwj1g, 0VCoeT-jjrIfzTCsOWz20...\n",
       "[CameraBoxComponent].box.center.x                                         [nan, nan, nan, nan, 1440.0252, nan, 28.263652...\n",
       "[CameraBoxComponent].box.center.y                                         [nan, nan, nan, nan, 718.1178300000001, nan, 7...\n",
       "[CameraBoxComponent].box.size.x                                           [nan, nan, nan, nan, 51.790379999999914, nan, ...\n",
       "[CameraBoxComponent].box.size.y                                           [nan, nan, nan, nan, 99.15962999999999, nan, 1...\n",
       "[CameraBoxComponent].type                                                 [nan, nan, nan, nan, 2.0, nan, 2.0, nan, nan, ...\n",
       "[CameraBoxComponent].difficulty_level.detection                           [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...\n",
       "[CameraBoxComponent].difficulty_level.tracking                            [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...\n",
       "[CameraImageComponent].image                                              [nan, nan, nan, nan, b'\\xff\\xd8\\xff\\xe0\\x00\\x1...\n",
       "[CameraImageComponent].pose.transform                                     [nan, nan, nan, nan, [0.6990588408049747, 0.71...\n",
       "[CameraImageComponent].velocity.linear_velocity.x                         [nan, nan, nan, nan, 1.3374745845794678, nan, ...\n",
       "[CameraImageComponent].velocity.linear_velocity.y                         [nan, nan, nan, nan, -1.359001636505127, nan, ...\n",
       "[CameraImageComponent].velocity.linear_velocity.z                         [nan, nan, nan, nan, 0.02728821150958538, nan,...\n",
       "[CameraImageComponent].velocity.angular_velocity.x                        [nan, nan, nan, nan, -0.0153918182477355, nan,...\n",
       "[CameraImageComponent].velocity.angular_velocity.y                        [nan, nan, nan, nan, 0.012218222953379154, nan...\n",
       "[CameraImageComponent].velocity.angular_velocity.z                        [nan, nan, nan, nan, 0.011144719086587429, nan...\n",
       "[CameraImageComponent].pose_timestamp                                     [nan, nan, nan, nan, 1552440195.413814, nan, 1...\n",
       "[CameraImageComponent].rolling_shutter_params.shutter                     [nan, nan, nan, nan, 0.0069807711988687515, na...\n",
       "[CameraImageComponent].rolling_shutter_params.camera_trigger_time         [nan, nan, nan, nan, 1552440195.3875952, nan, ...\n",
       "[CameraImageComponent].rolling_shutter_params.camera_readout_done_time    [nan, nan, nan, nan, 1552440195.438823, nan, 1...\n",
       "[LiDARBoxComponent].box.center.x                                          [-20.863535288122875, 18.184599214953778, 63.3...\n",
       "[LiDARBoxComponent].box.center.y                                          [3.0700130390359845, 11.52154547923783, -4.891...\n",
       "[LiDARBoxComponent].box.center.z                                          [0.9248285955182496, 0.5663701836315909, 0.617...\n",
       "[LiDARBoxComponent].box.size.x                                            [4.210511300963913, 1.043993850799436, 3.93165...\n",
       "[LiDARBoxComponent].box.size.y                                            [1.8452630397538268, 0.7544329631618889, 1.747...\n",
       "[LiDARBoxComponent].box.size.z                                            [1.669999999999959, 0.9800000000000182, 1.7000...\n",
       "[LiDARBoxComponent].box.heading                                           [0.05713253227596571, -1.6583762499768449, 0.0...\n",
       "[LiDARBoxComponent].type                                                  [1, 3, 1, 3, 2, 3, 2, 3, 1, 2, 2, 3, 1, 2, 2, ...\n",
       "[LiDARBoxComponent].num_lidar_points_in_box                               [441, 97, 32, 311, 63, 27, 159, 12, 37, 37, 44...\n",
       "[LiDARBoxComponent].num_top_lidar_points_in_box                           [438, 97, 32, 306, 63, 27, 159, 12, 37, 37, 44...\n",
       "[LiDARBoxComponent].speed.x                                               [0.0003420591302610144, -1.266784212881428e-28...\n",
       "[LiDARBoxComponent].speed.y                                               [-0.0010555099842807093, 0.0, -2.0268547406102...\n",
       "[LiDARBoxComponent].speed.z                                               [-0.01630478676015126, 6.33392106440714e-29, -...\n",
       "[LiDARBoxComponent].acceleration.x                                        [8.715455277306997e-14, 1.4075378651646187e-28...\n",
       "[LiDARBoxComponent].acceleration.y                                        [2.1571288960008079e-13, 0.0, 2.25206058426339...\n",
       "[LiDARBoxComponent].acceleration.z                                        [-2.0644732082949167e-14, -7.037689325823094e-...\n",
       "[LiDARBoxComponent].difficulty_level.detection                            [nan, nan, nan, nan, nan, 2.0, nan, 2.0, nan, ...\n",
       "[LiDARBoxComponent].difficulty_level.tracking                             [nan, nan, nan, nan, nan, 2.0, nan, 2.0, nan, ...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
